{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8sgNzUJGSqW"
      },
      "source": [
        "Ayda is working on presidential organization of Azerbaijan and she is ordered to remove all comments, both in Azerbaijani and English about racism (or other types of sarcasms) automatically from the President's twitter (or Instagram or Facebook) page. As there are lots of such comments she should create a classification model to do so.\n",
        "Please help her in finding such comments. You are allowed to use whatever tool you want but for the classification, you are just allowed to use LR to do so.\n",
        "Hint: Use translation python tools like 'mtranslate' for translation.\n",
        "\n",
        "Good luck.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OijKm2FEy64",
        "outputId": "89d8c95d-21a6-495c-cea7-467d83f641d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import os\n",
        "\n",
        "user = \"nabiyevnabi\"\n",
        "key = \"c048717f48dcbd89343bf759a45f8c68\"\n",
        "if '.kaggle' not in os.listdir('/root'):\n",
        "    !mkdir ~/.kaggle\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 666 /root/.kaggle/kaggle.json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "    f.write('{\"username\":\"%s\",\"key\":\"%s\"}' % (user, key))\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d rmsharks4/sarcasmania-dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sarcasmania-dataset.zip to /content\n",
            "\r  0% 0.00/1.59M [00:00<?, ?B/s]\n",
            "\r100% 1.59M/1.59M [00:00<00:00, 53.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SCX-OmgFE7R",
        "outputId": "9deacf4c-565d-4e49-8e0a-a5bc5d6ef1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip sarcasmania-dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sarcasmania-dataset.zip\n",
            "  inflating: sarcasmania-dataset.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-njaQygJFE-C"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "all_comments=pd.read_csv('/content/sarcasmania-dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky-xU7QenOUc",
        "outputId": "bc1a372d-c7e8-4462-a45f-246092f61eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        }
      },
      "source": [
        "pip install googletrans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans\n",
            "  Downloading https://files.pythonhosted.org/packages/71/3a/3b19effdd4c03958b90f40fe01c93de6d5280e03843cc5adf6956bfc9512/googletrans-3.0.0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.7MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/82/4bd4b7d9c0d1dc0fbfbc2a1e00138e7f3ab85bc239358fe9b78aa2ab586d/sniffio-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/07/12dd706501a3212a9774feb69d6a2333963a2da19ba98861ab23f2439f3d/hstspreload-2020.9.9-py3-none-any.whl (953kB)\n",
            "\u001b[K     |████████████████████████████████| 962kB 8.4MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Collecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.6MB/s \n",
            "\u001b[?25hCollecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 9.7MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans, contextvars\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.0.0-cp36-none-any.whl size=15736 sha256=a720d75ebcec7fd73082fa4d80139e097cce9a41b5abed84f39d03931d108c52\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/1a/a7/eaf4d7a3417a0c65796c547cff4deb6d79c7d14c2abd29273e\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=4f3e89ad182e9b2e2f89f5ca8f21599a09c03934acf27a957f580014ff55307e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built googletrans contextvars\n",
            "Installing collected packages: immutables, contextvars, sniffio, h11, hpack, hyperframe, h2, httpcore, hstspreload, rfc3986, httpx, googletrans\n",
            "Successfully installed contextvars-2.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.9.9 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnHYRx1Yb2Kt"
      },
      "source": [
        "Let's test the translate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcpAYwiZnSEj",
        "outputId": "abec345d-2235-4f13-e4a8-5a063d6675bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from googletrans import Translator,constants\n",
        "translator=Translator()\n",
        "translation=translator.translate(\"Sabir 2100 manat qazanir\",src='az')\n",
        "print(translation.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sabir earns 2,100 manats\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpSLDw-4of7c",
        "outputId": "13fdd599-d25e-4c4e-b39b-2b015ef2b111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "translation=translator.translate(all_comments.iloc[8,1],src='en',dest='az')\n",
        "print(translation.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bu səhər 10 km piyada gedin. Zəhmli bir iş gördük.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK3q8f-advpD"
      },
      "source": [
        "So,the translator is quite good"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiHkxCTWFFAo",
        "outputId": "2510432d-bb66-4cb3-f98d-c20bc301cfb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "all_comments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>humor</th>\n",
              "      <th>insult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>@0430yes i hope youre lurking rn. i want to li...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>05 really taught me a valuable lesson I'm neve...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>@098BERRY Never had a voice to protest, so you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>@0hMySt4rs Rest in peace &amp; love to you and you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>100 days until Christmas! 🌲 #too soon #not rea...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39775</th>\n",
              "      <td>39776</td>\n",
              "      <td>@Zendaya I could see the makeup artists giving...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39776</th>\n",
              "      <td>39777</td>\n",
              "      <td>@ZiggiWatkins11 Slvr... That's great name #NOT...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39777</th>\n",
              "      <td>39778</td>\n",
              "      <td>@zoso4986 @Nero He is the fag we need but not ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39778</th>\n",
              "      <td>39779</td>\n",
              "      <td>Zuma sounding like Kanye West right now trying...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39779</th>\n",
              "      <td>39780</td>\n",
              "      <td>@ZZUCRU @UWDawgPack So true. Students - stick ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39780 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet  ...  humor  insult\n",
              "0          1  @0430yes i hope youre lurking rn. i want to li...  ...      0       0\n",
              "1          2  05 really taught me a valuable lesson I'm neve...  ...      1       1\n",
              "2          3  @098BERRY Never had a voice to protest, so you...  ...      0       0\n",
              "3          4  @0hMySt4rs Rest in peace & love to you and you...  ...      0       1\n",
              "4          5  100 days until Christmas! 🌲 #too soon #not rea...  ...      0       1\n",
              "...      ...                                                ...  ...    ...     ...\n",
              "39775  39776  @Zendaya I could see the makeup artists giving...  ...      0       1\n",
              "39776  39777  @ZiggiWatkins11 Slvr... That's great name #NOT...  ...      1       0\n",
              "39777  39778  @zoso4986 @Nero He is the fag we need but not ...  ...      1       1\n",
              "39778  39779  Zuma sounding like Kanye West right now trying...  ...      0       1\n",
              "39779  39780  @ZZUCRU @UWDawgPack So true. Students - stick ...  ...      1       0\n",
              "\n",
              "[39780 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMm8jwOtd2M5"
      },
      "source": [
        "Shuffling the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcpnM08atZP4",
        "outputId": "35b00f5f-b4c9-429d-ee4e-09fe57864cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "np.random.seed(128)\n",
        "shuffled_comments=all_comments.sample(frac=1).reset_index(drop=True)\n",
        "shuffled_comments"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>humor</th>\n",
              "      <th>insult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>34247</td>\n",
              "      <td>RT I'm Not Saying that #Hitler Was A Great Guy...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36241</td>\n",
              "      <td>Texting is cool. You sound polite to the recei...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4020</td>\n",
              "      <td>Eraticus take a sickle and bring back sprouts :)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24509</td>\n",
              "      <td>@GetIt_Back20 u know me, im nothing like \" the...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35193</td>\n",
              "      <td>seriously my favorite thing is when people rem...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39775</th>\n",
              "      <td>8632</td>\n",
              "      <td>I love your voice, and your Eyes, and your smi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39776</th>\n",
              "      <td>21618</td>\n",
              "      <td>After a 8am meeting now to domestic abuse trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39777</th>\n",
              "      <td>9530</td>\n",
              "      <td>I sleep with two knives in my room</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39778</th>\n",
              "      <td>30182</td>\n",
              "      <td>kkk are the police are the kkk are the police....</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39779</th>\n",
              "      <td>23636</td>\n",
              "      <td>Don't be ashamed of who you are. That's your p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39780 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet  ...  humor  insult\n",
              "0      34247  RT I'm Not Saying that #Hitler Was A Great Guy...  ...      1       1\n",
              "1      36241  Texting is cool. You sound polite to the recei...  ...      0       1\n",
              "2       4020   Eraticus take a sickle and bring back sprouts :)  ...      0       1\n",
              "3      24509  @GetIt_Back20 u know me, im nothing like \" the...  ...      0       0\n",
              "4      35193  seriously my favorite thing is when people rem...  ...      1       1\n",
              "...      ...                                                ...  ...    ...     ...\n",
              "39775   8632  I love your voice, and your Eyes, and your smi...  ...      0       1\n",
              "39776  21618  After a 8am meeting now to domestic abuse trai...  ...      0       0\n",
              "39777   9530                 I sleep with two knives in my room  ...      1       0\n",
              "39778  30182  kkk are the police are the kkk are the police....  ...      1       1\n",
              "39779  23636  Don't be ashamed of who you are. That's your p...  ...      0       0\n",
              "\n",
              "[39780 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIX_izXSd7KN"
      },
      "source": [
        "I will pick 1000 samples to make translation process *faster*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGKy8Tv8uc0W"
      },
      "source": [
        "shuffled_comments=shuffled_comments.iloc[:1000,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JvS_9WVpsPZ"
      },
      "source": [
        "az_tweets=[]\n",
        "for tweet in shuffled_comments['tweet']:\n",
        "  translation=translator.translate(tweet,src='en',dest='az')\n",
        "  az_tweets.append(translation.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTAi_4YN4zPF"
      },
      "source": [
        "sarcasm=shuffled_comments.iloc[:1000,2]\n",
        "humor=shuffled_comments.iloc[:1000,3]\n",
        "insult=shuffled_comments.iloc[:1000,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yOfW5I-eJOv"
      },
      "source": [
        "Creating the dataset,that contains only translated tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXltpL6f4_Vv"
      },
      "source": [
        "azerbaijani_dataset=pd.DataFrame({'tweet':az_tweets,'sarcasm':sarcasm,'humor':humor,'insult':insult})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48-4bZgB63-V",
        "outputId": "fe62448f-b54e-400e-dcd3-10311d837558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "azerbaijani_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>humor</th>\n",
              "      <th>insult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT # Hitlerin Möhtəşəm Bir Adam olduğunu Demir...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mesaj yazmaq yaxşıdır. Alıcına nəzakətli səs v...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Eraticus bir oraq götürüb cücərtilər gətirir :)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@ GetIt_Back20 məni tanıyırsınız, \"onlar\" kimi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ciddi mənim ən sevdiyim şey insanlar dedikləri...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>LAX vasitəsilə bu qaçış üçün tamamilə enerjim ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Ah yes that was a fantastic feeling let's dig ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>mia bir selfini sevir .. # deyil # sərcasm</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Şampan, səhər yeməyi, gəzinti və sonra bira pi...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Gəlin bu şərabın məni mənfilikdən təmizlədiyin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 tweet  sarcasm  humor  insult\n",
              "0    RT # Hitlerin Möhtəşəm Bir Adam olduğunu Demir...        1      1       1\n",
              "1    Mesaj yazmaq yaxşıdır. Alıcına nəzakətli səs v...        1      0       1\n",
              "2      Eraticus bir oraq götürüb cücərtilər gətirir :)        0      0       1\n",
              "3    @ GetIt_Back20 məni tanıyırsınız, \"onlar\" kimi...        1      0       0\n",
              "4    ciddi mənim ən sevdiyim şey insanlar dedikləri...        1      1       1\n",
              "..                                                 ...      ...    ...     ...\n",
              "995  LAX vasitəsilə bu qaçış üçün tamamilə enerjim ...        1      0       0\n",
              "996  Ah yes that was a fantastic feeling let's dig ...        0      0       0\n",
              "997         mia bir selfini sevir .. # deyil # sərcasm        1      1       0\n",
              "998  Şampan, səhər yeməyi, gəzinti və sonra bira pi...        0      1       1\n",
              "999  Gəlin bu şərabın məni mənfilikdən təmizlədiyin...        1      1       0\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnm2mYXeQ9g"
      },
      "source": [
        "I will work with 10000 tweets,there will be 9000 original tweets and 1000 translated tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipts1RTplwoG"
      },
      "source": [
        "all_comments=all_comments.iloc[:9000,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VxmQnUJ7mi1"
      },
      "source": [
        "overall=pd.concat([all_comments,azerbaijani_dataset])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMo9nsc_7y4j",
        "outputId": "a1dd7d44-21e8-4621-d4ad-7633fea9fab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "overall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>humor</th>\n",
              "      <th>insult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>@0430yes i hope youre lurking rn. i want to li...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>05 really taught me a valuable lesson I'm neve...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>@098BERRY Never had a voice to protest, so you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>@0hMySt4rs Rest in peace &amp; love to you and you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>100 days until Christmas! 🌲 #too soon #not rea...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>NaN</td>\n",
              "      <td>LAX vasitəsilə bu qaçış üçün tamamilə enerjim ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Ah yes that was a fantastic feeling let's dig ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>NaN</td>\n",
              "      <td>mia bir selfini sevir .. # deyil # sərcasm</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Şampan, səhər yeməyi, gəzinti və sonra bira pi...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Gəlin bu şərabın məni mənfilikdən təmizlədiyin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet  ...  humor  insult\n",
              "0    1.0  @0430yes i hope youre lurking rn. i want to li...  ...      0       0\n",
              "1    2.0  05 really taught me a valuable lesson I'm neve...  ...      1       1\n",
              "2    3.0  @098BERRY Never had a voice to protest, so you...  ...      0       0\n",
              "3    4.0  @0hMySt4rs Rest in peace & love to you and you...  ...      0       1\n",
              "4    5.0  100 days until Christmas! 🌲 #too soon #not rea...  ...      0       1\n",
              "..   ...                                                ...  ...    ...     ...\n",
              "995  NaN  LAX vasitəsilə bu qaçış üçün tamamilə enerjim ...  ...      0       0\n",
              "996  NaN  Ah yes that was a fantastic feeling let's dig ...  ...      0       0\n",
              "997  NaN         mia bir selfini sevir .. # deyil # sərcasm  ...      1       0\n",
              "998  NaN  Şampan, səhər yeməyi, gəzinti və sonra bira pi...  ...      1       1\n",
              "999  NaN  Gəlin bu şərabın məni mənfilikdən təmizlədiyin...  ...      1       0\n",
              "\n",
              "[10000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Toq6PlATeki8"
      },
      "source": [
        "We should shuffle one more time,because first 9000 rows contains only original tweets.We must shuffle the data to make the learning process for LR more better"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01MyyIjo79eC",
        "outputId": "fd57543b-910e-44ff-c157-305282a9a0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "np.random.seed(130)\n",
        "shuffled_overall=overall.sample(frac=1).reset_index(drop=True)\n",
        "shuffled_overall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sarcasm</th>\n",
              "      <th>humor</th>\n",
              "      <th>insult</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3706.0</td>\n",
              "      <td>do you ever go to school confident in what you...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>878.0</td>\n",
              "      <td>@annetut25... act as as ice you know. We can j...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3625.0</td>\n",
              "      <td>Double Sexy Package Is The Best Type Of Package</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>798.0</td>\n",
              "      <td>And that seals it for me 'cause this woman has...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8410.0</td>\n",
              "      <td>I lost the voicemail that Brody left me in Feb...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>7691.0</td>\n",
              "      <td>I had all weekend to read the shit my quiz is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Erkən oyandıqdan sonra yenidən yuxuya getmək d...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>7966.0</td>\n",
              "      <td>I hate when girls act like they know me person...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>7286.0</td>\n",
              "      <td>If a mf don't care if you eat the whole day th...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>8602.0</td>\n",
              "      <td>I love to see little babies chasing kitties 😄 😄 😄</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                              tweet  ...  humor  insult\n",
              "0     3706.0  do you ever go to school confident in what you...  ...      0       0\n",
              "1      878.0  @annetut25... act as as ice you know. We can j...  ...      0       1\n",
              "2     3625.0    Double Sexy Package Is The Best Type Of Package  ...      1       1\n",
              "3      798.0  And that seals it for me 'cause this woman has...  ...      0       0\n",
              "4     8410.0  I lost the voicemail that Brody left me in Feb...  ...      1       1\n",
              "...      ...                                                ...  ...    ...     ...\n",
              "9995  7691.0  I had all weekend to read the shit my quiz is ...  ...      0       0\n",
              "9996     NaN  Erkən oyandıqdan sonra yenidən yuxuya getmək d...  ...      1       0\n",
              "9997  7966.0  I hate when girls act like they know me person...  ...      0       1\n",
              "9998  7286.0  If a mf don't care if you eat the whole day th...  ...      0       1\n",
              "9999  8602.0  I love to see little babies chasing kitties 😄 😄 😄  ...      1       0\n",
              "\n",
              "[10000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lJ3jEL0e0-m"
      },
      "source": [
        "So,we have 3 ways  how to make model classify the text.\n",
        "First one is:\n",
        "\n",
        "*   Take the overall dataset and tokenize the text in word level\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_bfoXGpFFF8"
      },
      "source": [
        "import tensorflow as tf\n",
        "t=tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=20000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
        "    split=' ', char_level=False, oov_token = 'sabir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xclgh4Z6AX8L"
      },
      "source": [
        "tweets=np.array(overall['tweet'])\n",
        "labels=np.array(overall[['sarcasm','humor','insult']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgEfeZu0GNk3"
      },
      "source": [
        "t.fit_on_texts(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWPS0F_IGNpO",
        "outputId": "226db7db-81c4-4c3f-c71c-d32f3c4d92f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sorted(t.word_index.items(),key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sabir', 1),\n",
              " ('i', 2),\n",
              " ('to', 3),\n",
              " ('the', 4),\n",
              " ('you', 5),\n",
              " ('a', 6),\n",
              " ('and', 7),\n",
              " ('my', 8),\n",
              " ('of', 9),\n",
              " ('in', 10),\n",
              " ('is', 11),\n",
              " ('for', 12),\n",
              " ('it', 13),\n",
              " ('love', 14),\n",
              " ('that', 15),\n",
              " ('so', 16),\n",
              " ('me', 17),\n",
              " ('have', 18),\n",
              " ('on', 19),\n",
              " ('this', 20),\n",
              " ('be', 21),\n",
              " ('with', 22),\n",
              " (\"i'm\", 23),\n",
              " ('your', 24),\n",
              " ('just', 25),\n",
              " ('but', 26),\n",
              " ('not', 27),\n",
              " ('like', 28),\n",
              " ('at', 29),\n",
              " (\"don't\", 30),\n",
              " ('all', 31),\n",
              " ('do', 32),\n",
              " ('when', 33),\n",
              " ('are', 34),\n",
              " ('day', 35),\n",
              " ('if', 36),\n",
              " ('hate', 37),\n",
              " ('get', 38),\n",
              " ('was', 39),\n",
              " ('good', 40),\n",
              " ('up', 41),\n",
              " ('can', 42),\n",
              " ('how', 43),\n",
              " ('😂', 44),\n",
              " ('people', 45),\n",
              " ('happy', 46),\n",
              " ('they', 47),\n",
              " ('great', 48),\n",
              " ('u', 49),\n",
              " ('out', 50),\n",
              " ('about', 51),\n",
              " ('much', 52),\n",
              " (\"can't\", 53),\n",
              " ('an', 54),\n",
              " ('we', 55),\n",
              " ('what', 56),\n",
              " (\"it's\", 57),\n",
              " ('one', 58),\n",
              " ('know', 59),\n",
              " ('sarcasm', 60),\n",
              " ('really', 61),\n",
              " ('no', 62),\n",
              " ('as', 63),\n",
              " ('time', 64),\n",
              " ('wait', 65),\n",
              " ('shit', 66),\n",
              " ('from', 67),\n",
              " ('go', 68),\n",
              " ('who', 69),\n",
              " ('had', 70),\n",
              " ('he', 71),\n",
              " (\"you're\", 72),\n",
              " ('lol', 73),\n",
              " ('being', 74),\n",
              " ('or', 75),\n",
              " ('will', 76),\n",
              " ('now', 77),\n",
              " ('want', 78),\n",
              " ('too', 79),\n",
              " ('back', 80),\n",
              " ('ever', 81),\n",
              " ('see', 82),\n",
              " ('more', 83),\n",
              " ('by', 84),\n",
              " ('birthday', 85),\n",
              " ('her', 86),\n",
              " ('today', 87),\n",
              " ('am', 88),\n",
              " ('got', 89),\n",
              " ('life', 90),\n",
              " ('going', 91),\n",
              " ('best', 92),\n",
              " ('work', 93),\n",
              " ('because', 94),\n",
              " ('always', 95),\n",
              " ('night', 96),\n",
              " ('bir', 97),\n",
              " ('need', 98),\n",
              " ('make', 99),\n",
              " ('hope', 100),\n",
              " ('home', 101),\n",
              " ('then', 102),\n",
              " ('she', 103),\n",
              " ('why', 104),\n",
              " ('school', 105),\n",
              " ('think', 106),\n",
              " ('been', 107),\n",
              " ('them', 108),\n",
              " ('has', 109),\n",
              " ('right', 110),\n",
              " ('say', 111),\n",
              " ('would', 112),\n",
              " ('even', 113),\n",
              " ('never', 114),\n",
              " ('im', 115),\n",
              " ('his', 116),\n",
              " ('our', 117),\n",
              " ('hillaryclinton', 118),\n",
              " ('thank', 119),\n",
              " ('və', 120),\n",
              " ('here', 121),\n",
              " ('some', 122),\n",
              " ('could', 123),\n",
              " ('2', 124),\n",
              " ('fun', 125),\n",
              " ('off', 126),\n",
              " ('😍', 127),\n",
              " ('better', 128),\n",
              " ('new', 129),\n",
              " ('look', 130),\n",
              " ('its', 131),\n",
              " ('only', 132),\n",
              " ('someone', 133),\n",
              " ('did', 134),\n",
              " ('❤️', 135),\n",
              " ('😭', 136),\n",
              " ('feeling', 137),\n",
              " ('there', 138),\n",
              " ('last', 139),\n",
              " ('üçün', 140),\n",
              " ('feel', 141),\n",
              " ('morning', 142),\n",
              " ('fuck', 143),\n",
              " ('after', 144),\n",
              " ('their', 145),\n",
              " ('than', 146),\n",
              " ('still', 147),\n",
              " ('getting', 148),\n",
              " ('pretty', 149),\n",
              " ('tonight', 150),\n",
              " ('please', 151),\n",
              " ('awesome', 152),\n",
              " ('having', 153),\n",
              " ('nice', 154),\n",
              " ('first', 155),\n",
              " ('give', 156),\n",
              " (\"that's\", 157),\n",
              " ('these', 158),\n",
              " (\"i'll\", 159),\n",
              " ('sleep', 160),\n",
              " ('tomorrow', 161),\n",
              " ('come', 162),\n",
              " ('everyone', 163),\n",
              " ('him', 164),\n",
              " ('year', 165),\n",
              " ('friends', 166),\n",
              " ('over', 167),\n",
              " ('3', 168),\n",
              " ('should', 169),\n",
              " ('thanks', 170),\n",
              " ('game', 171),\n",
              " ('every', 172),\n",
              " ('sick', 173),\n",
              " ('gonna', 174),\n",
              " ('ur', 175),\n",
              " ('amazing', 176),\n",
              " ('bu', 177),\n",
              " ('way', 178),\n",
              " ('long', 179),\n",
              " ('thing', 180),\n",
              " ('other', 181),\n",
              " ('beautiful', 182),\n",
              " ('take', 183),\n",
              " ('looking', 184),\n",
              " ('down', 185),\n",
              " ('bed', 186),\n",
              " ('person', 187),\n",
              " ('world', 188),\n",
              " ('another', 189),\n",
              " ('nothing', 190),\n",
              " ('us', 191),\n",
              " ('full', 192),\n",
              " ('any', 193),\n",
              " (\"'\", 194),\n",
              " ('cant', 195),\n",
              " ('1', 196),\n",
              " ('things', 197),\n",
              " ('very', 198),\n",
              " ('miss', 199),\n",
              " ('something', 200),\n",
              " ('class', 201),\n",
              " ('man', 202),\n",
              " ('real', 203),\n",
              " ('everything', 204),\n",
              " ('bad', 205),\n",
              " ('made', 206),\n",
              " ('guys', 207),\n",
              " ('doing', 208),\n",
              " ('start', 209),\n",
              " ('❤', 210),\n",
              " ('tell', 211),\n",
              " (\"i've\", 212),\n",
              " ('5', 213),\n",
              " ('😊', 214),\n",
              " ('keep', 215),\n",
              " ('free', 216),\n",
              " ('😘', 217),\n",
              " ('week', 218),\n",
              " ('such', 219),\n",
              " ('çox', 220),\n",
              " (\"didn't\", 221),\n",
              " ('well', 222),\n",
              " ('hair', 223),\n",
              " ('glad', 224),\n",
              " ('were', 225),\n",
              " ('cnn', 226),\n",
              " ('fucking', 227),\n",
              " ('forward', 228),\n",
              " ('again', 229),\n",
              " ('face', 230),\n",
              " ('next', 231),\n",
              " ('excited', 232),\n",
              " ('god', 233),\n",
              " ('care', 234),\n",
              " ('4', 235),\n",
              " ('watch', 236),\n",
              " ('dont', 237),\n",
              " ('😩', 238),\n",
              " ('test', 239),\n",
              " ('cool', 240),\n",
              " ('yay', 241),\n",
              " ('weekend', 242),\n",
              " ('into', 243),\n",
              " ('actually', 244),\n",
              " ('before', 245),\n",
              " ('family', 246),\n",
              " ('bitch', 247),\n",
              " ('little', 248),\n",
              " ('friend', 249),\n",
              " ('phone', 250),\n",
              " ('already', 251),\n",
              " ('where', 252),\n",
              " ('enjoy', 253),\n",
              " ('guess', 254),\n",
              " ('sure', 255),\n",
              " ('stay', 256),\n",
              " ('foxnews', 257),\n",
              " ('old', 258),\n",
              " ('girl', 259),\n",
              " ('those', 260),\n",
              " ('money', 261),\n",
              " ('started', 262),\n",
              " ('find', 263),\n",
              " ('lot', 264),\n",
              " ('makes', 265),\n",
              " ('help', 266),\n",
              " ('big', 267),\n",
              " ('bc', 268),\n",
              " ('cause', 269),\n",
              " ('sarkazm', 270),\n",
              " ('many', 271),\n",
              " ('most', 272),\n",
              " ('girls', 273),\n",
              " ('show', 274),\n",
              " ('same', 275),\n",
              " ('days', 276),\n",
              " ('food', 277),\n",
              " ('anything', 278),\n",
              " ('ass', 279),\n",
              " ('let', 280),\n",
              " ('hey', 281),\n",
              " ('stop', 282),\n",
              " ('rt', 283),\n",
              " ('done', 284),\n",
              " ('wish', 285),\n",
              " ('oh', 286),\n",
              " ('making', 287),\n",
              " ('kids', 288),\n",
              " ('talk', 289),\n",
              " ('song', 290),\n",
              " ('room', 291),\n",
              " ('enough', 292),\n",
              " ('meet', 293),\n",
              " ('while', 294),\n",
              " ('years', 295),\n",
              " ('credit', 296),\n",
              " ('lost', 297),\n",
              " ('away', 298),\n",
              " ('around', 299),\n",
              " ('said', 300),\n",
              " ('put', 301),\n",
              " ('wanna', 302),\n",
              " ('though', 303),\n",
              " ('also', 304),\n",
              " ('own', 305),\n",
              " ('o', 306),\n",
              " ('yaxşı', 307),\n",
              " (\"he's\", 308),\n",
              " ('house', 309),\n",
              " ('haha', 310),\n",
              " ('football', 311),\n",
              " ('play', 312),\n",
              " ('cute', 313),\n",
              " ('mean', 314),\n",
              " ('😒', 315),\n",
              " ('twitter', 316),\n",
              " ('believe', 317),\n",
              " ('watching', 318),\n",
              " ('literally', 319),\n",
              " (\"they're\", 320),\n",
              " ('without', 321),\n",
              " ('two', 322),\n",
              " ('friday', 323),\n",
              " (\"doesn't\", 324),\n",
              " ('shitty', 325),\n",
              " ('does', 326),\n",
              " ('break', 327),\n",
              " ('edirəm', 328),\n",
              " ('cold', 329),\n",
              " ('funny', 330),\n",
              " ('video', 331),\n",
              " ('trump', 332),\n",
              " ('seeing', 333),\n",
              " ('w', 334),\n",
              " ('myself', 335),\n",
              " ('together', 336),\n",
              " ('waking', 337),\n",
              " ('baby', 338),\n",
              " ('through', 339),\n",
              " ('appreciate', 340),\n",
              " ('super', 341),\n",
              " ('wow', 342),\n",
              " ('hard', 343),\n",
              " ('music', 344),\n",
              " ('heart', 345),\n",
              " ('hot', 346),\n",
              " ('finally', 347),\n",
              " ('trying', 348),\n",
              " ('bring', 349),\n",
              " ('follow', 350),\n",
              " ('until', 351),\n",
              " ('soon', 352),\n",
              " ('smoke', 353),\n",
              " ('damn', 354),\n",
              " ('remember', 355),\n",
              " ('mood', 356),\n",
              " ('wrong', 357),\n",
              " ('since', 358),\n",
              " ('check', 359),\n",
              " ('gotta', 360),\n",
              " ('early', 361),\n",
              " ('camerondallas', 362),\n",
              " ('deyil', 363),\n",
              " ('laughed', 364),\n",
              " ('end', 365),\n",
              " ('homework', 366),\n",
              " ('😁', 367),\n",
              " ('else', 368),\n",
              " ('n', 369),\n",
              " ('harry', 370),\n",
              " ('dead', 371),\n",
              " ('high', 372),\n",
              " ('whole', 373),\n",
              " (\"ain't\", 374),\n",
              " ('lmao', 375),\n",
              " ('fact', 376),\n",
              " ('anyone', 377),\n",
              " ('mən', 378),\n",
              " ('sevirəm', 379),\n",
              " ('live', 380),\n",
              " ('reason', 381),\n",
              " ('season', 382),\n",
              " (\"there's\", 383),\n",
              " ('finish', 384),\n",
              " ('hurt', 385),\n",
              " ('women', 386),\n",
              " ('mind', 387),\n",
              " ('under', 388),\n",
              " ('yet', 389),\n",
              " ('dream', 390),\n",
              " ('dumb', 391),\n",
              " ('mom', 392),\n",
              " ('use', 393),\n",
              " ('playing', 394),\n",
              " ('woman', 395),\n",
              " (\"she's\", 396),\n",
              " ('qədər', 397),\n",
              " ('ya', 398),\n",
              " ('6', 399),\n",
              " ('black', 400),\n",
              " ('late', 401),\n",
              " ('job', 402),\n",
              " ('hours', 403),\n",
              " ('left', 404),\n",
              " ('tweet', 405),\n",
              " ('children', 406),\n",
              " ('favorite', 407),\n",
              " ('coming', 408),\n",
              " ('hear', 409),\n",
              " ('fan', 410),\n",
              " ('drive', 411),\n",
              " ('looks', 412),\n",
              " ('must', 413),\n",
              " ('successful', 414),\n",
              " ('found', 415),\n",
              " ('kimi', 416),\n",
              " ('half', 417),\n",
              " ('yeah', 418),\n",
              " ('loved', 419),\n",
              " ('handle', 420),\n",
              " ('which', 421),\n",
              " ('okay', 422),\n",
              " ('fantastic', 423),\n",
              " ('true', 424),\n",
              " ('times', 425),\n",
              " ('shame', 426),\n",
              " ('x', 427),\n",
              " ('idk', 428),\n",
              " ('business', 429),\n",
              " ('d', 430),\n",
              " ('crazy', 431),\n",
              " ('teacher', 432),\n",
              " ('stupid', 433),\n",
              " ('understand', 434),\n",
              " ('shower', 435),\n",
              " ('probably', 436),\n",
              " ('da', 437),\n",
              " ('hər', 438),\n",
              " ('christmas', 439),\n",
              " ('summer', 440),\n",
              " ('part', 441),\n",
              " ('omg', 442),\n",
              " ('yourself', 443),\n",
              " ('goodnight', 444),\n",
              " ('agree', 445),\n",
              " ('parents', 446),\n",
              " (\"won't\", 447),\n",
              " ('—', 448),\n",
              " ('10', 449),\n",
              " ('says', 450),\n",
              " ('worst', 451),\n",
              " ('almost', 452),\n",
              " (\"i'd\", 453),\n",
              " ('hillary', 454),\n",
              " ('forget', 455),\n",
              " ('pass', 456),\n",
              " ('sorry', 457),\n",
              " ('məni', 458),\n",
              " ('failed', 459),\n",
              " ('try', 460),\n",
              " ('working', 461),\n",
              " ('amazin', 462),\n",
              " ('tv', 463),\n",
              " ('judge', 464),\n",
              " ('proud', 465),\n",
              " ('də', 466),\n",
              " ('yes', 467),\n",
              " (\"haven't\", 468),\n",
              " ('guy', 469),\n",
              " ('goes', 470),\n",
              " ('both', 471),\n",
              " ('swear', 472),\n",
              " (\"isn't\", 473),\n",
              " ('drinking', 474),\n",
              " ('change', 475),\n",
              " ('win', 476),\n",
              " ('smile', 477),\n",
              " ('ki', 478),\n",
              " ('amma', 479),\n",
              " ('ən', 480),\n",
              " ('peace', 481),\n",
              " ('ready', 482),\n",
              " ('r', 483),\n",
              " ('card', 484),\n",
              " ('thought', 485),\n",
              " ('place', 486),\n",
              " ('sister', 487),\n",
              " ('talking', 488),\n",
              " ('kind', 489),\n",
              " ('name', 490),\n",
              " ('relationship', 491),\n",
              " ('dark', 492),\n",
              " ('leave', 493),\n",
              " ('safe', 494),\n",
              " ('head', 495),\n",
              " ('boyfriend', 496),\n",
              " ('each', 497),\n",
              " ('called', 498),\n",
              " ('news', 499),\n",
              " ('eat', 500),\n",
              " ('perfect', 501),\n",
              " ('blessed', 502),\n",
              " ('physics', 503),\n",
              " ('might', 504),\n",
              " ('wonderful', 505),\n",
              " ('suck', 506),\n",
              " ('sarcastic', 507),\n",
              " ('daha', 508),\n",
              " ('butt', 509),\n",
              " ('may', 510),\n",
              " ('saying', 511),\n",
              " ('drink', 512),\n",
              " ('7', 513),\n",
              " ('gets', 514),\n",
              " ('mad', 515),\n",
              " ('realdonaldtrump', 516),\n",
              " ('charge', 517),\n",
              " ('happen', 518),\n",
              " ('party', 519),\n",
              " ('honestly', 520),\n",
              " ('side', 521),\n",
              " ('packed', 522),\n",
              " ('top', 523),\n",
              " ('meeting', 524),\n",
              " ('team', 525),\n",
              " ('rain', 526),\n",
              " ('ask', 527),\n",
              " ('stressed', 528),\n",
              " ('heard', 529),\n",
              " ('freaking', 530),\n",
              " ('t', 531),\n",
              " ('movie', 532),\n",
              " ('happening', 533),\n",
              " ('read', 534),\n",
              " ('falling', 535),\n",
              " ('gone', 536),\n",
              " ('şey', 537),\n",
              " ('sweet', 538),\n",
              " ('reply', 539),\n",
              " ('hoping', 540),\n",
              " ('bit', 541),\n",
              " ('tired', 542),\n",
              " ('till', 543),\n",
              " ('needs', 544),\n",
              " ('history', 545),\n",
              " ('lovely', 546),\n",
              " ('tho', 547),\n",
              " ('via', 548),\n",
              " ('conversation', 549),\n",
              " ('hi', 550),\n",
              " ('listen', 551),\n",
              " ('faster', 552),\n",
              " ('boy', 553),\n",
              " ('ago', 554),\n",
              " ('shocked', 555),\n",
              " ('thanksgiving', 556),\n",
              " ('waiting', 557),\n",
              " ('☺️', 558),\n",
              " ('lie', 559),\n",
              " ('success', 560),\n",
              " ('few', 561),\n",
              " ('wtf', 562),\n",
              " ('tea', 563),\n",
              " ('set', 564),\n",
              " ('interesting', 565),\n",
              " ('bus', 566),\n",
              " ('sonra', 567),\n",
              " ('yesterday', 568),\n",
              " ('mtvstars', 569),\n",
              " ('convention', 570),\n",
              " ('car', 571),\n",
              " ('fall', 572),\n",
              " ('release', 573),\n",
              " ('learn', 574),\n",
              " ('track', 575),\n",
              " ('cnnpolitics', 576),\n",
              " ('country', 577),\n",
              " ('control', 578),\n",
              " ('call', 579),\n",
              " ('hungry', 580),\n",
              " ('wanted', 581),\n",
              " ('told', 582),\n",
              " ('smell', 583),\n",
              " ('styles', 584),\n",
              " ('blessing', 585),\n",
              " ('heç', 586),\n",
              " ('boring', 587),\n",
              " ('b', 588),\n",
              " ('gas', 589),\n",
              " ('worse', 590),\n",
              " ('maybe', 591),\n",
              " ('hour', 592),\n",
              " ('cantwait', 593),\n",
              " ('following', 594),\n",
              " ('pay', 595),\n",
              " ('gorgeous', 596),\n",
              " ('fridge', 597),\n",
              " ('college', 598),\n",
              " ('bestfriend', 599),\n",
              " (\"wasn't\", 600),\n",
              " ('hilarious', 601),\n",
              " ('point', 602),\n",
              " ('asleep', 603),\n",
              " ('😔', 604),\n",
              " ('30', 605),\n",
              " ('fighting', 606),\n",
              " ('fire', 607),\n",
              " ('months', 608),\n",
              " ('hell', 609),\n",
              " ('hit', 610),\n",
              " ('absolutely', 611),\n",
              " ('quite', 612),\n",
              " ('youtube', 613),\n",
              " ('album', 614),\n",
              " ('hug', 615),\n",
              " ('example', 616),\n",
              " ('fight', 617),\n",
              " ('laugh', 618),\n",
              " ('hoes', 619),\n",
              " ('subtle', 620),\n",
              " ('ddlovato', 621),\n",
              " ('ilə', 622),\n",
              " ('rest', 623),\n",
              " ('limit', 624),\n",
              " ('alone', 625),\n",
              " ('wake', 626),\n",
              " ('buy', 627),\n",
              " ('wants', 628),\n",
              " ('20', 629),\n",
              " ('white', 630),\n",
              " ('cat', 631),\n",
              " ('hehe', 632),\n",
              " ('least', 633),\n",
              " ('rolling', 634),\n",
              " (\"y'all\", 635),\n",
              " ('ideas', 636),\n",
              " ('once', 637),\n",
              " ('michael5sos', 638),\n",
              " ('rights', 639),\n",
              " ('used', 640),\n",
              " ('move', 641),\n",
              " ('deserve', 642),\n",
              " ('able', 643),\n",
              " ('lying', 644),\n",
              " ('everybody', 645),\n",
              " ('post', 646),\n",
              " ('dress', 647),\n",
              " ('stuff', 648),\n",
              " (\"we're\", 649),\n",
              " ('ok', 650),\n",
              " ('classes', 651),\n",
              " ('dear', 652),\n",
              " ('awkward', 653),\n",
              " ('anymore', 654),\n",
              " ('easily', 655),\n",
              " ('nə', 656),\n",
              " ('word', 657),\n",
              " ('s', 658),\n",
              " ('hehehe', 659),\n",
              " ('weeks', 660),\n",
              " ('different', 661),\n",
              " ('outside', 662),\n",
              " ('giving', 663),\n",
              " ('american', 664),\n",
              " ('past', 665),\n",
              " ('support', 666),\n",
              " ('nobody', 667),\n",
              " ('stand', 668),\n",
              " ('creepy', 669),\n",
              " ('wonder', 670),\n",
              " ('built', 671),\n",
              " ('ppl', 672),\n",
              " ('came', 673),\n",
              " ('bestfeelingever', 674),\n",
              " ('gün', 675),\n",
              " ('sit', 676),\n",
              " ('later', 677),\n",
              " ('boys', 678),\n",
              " ('eyes', 679),\n",
              " ('intimidated', 680),\n",
              " ('due', 681),\n",
              " ('book', 682),\n",
              " ('idea', 683),\n",
              " ('lunch', 684),\n",
              " ('text', 685),\n",
              " ('seen', 686),\n",
              " ('words', 687),\n",
              " ('direction', 688),\n",
              " ('prayers', 689),\n",
              " ('weird', 690),\n",
              " ('feels', 691),\n",
              " ('during', 692),\n",
              " ('smart', 693),\n",
              " ('9', 694),\n",
              " ('weather', 695),\n",
              " ('abc', 696),\n",
              " ('singing', 697),\n",
              " ('men', 698),\n",
              " ('story', 699),\n",
              " ('😷', 700),\n",
              " (\"let's\", 701),\n",
              " ('careless', 702),\n",
              " ('😑', 703),\n",
              " ('af', 704),\n",
              " ('keeps', 705),\n",
              " ('run', 706),\n",
              " ('chance', 707),\n",
              " ('realize', 708),\n",
              " (\"here's\", 709),\n",
              " ('hiss', 710),\n",
              " ('var', 711),\n",
              " ('saturday', 712),\n",
              " (\"you've\", 713),\n",
              " ('against', 714),\n",
              " ('arrested', 715),\n",
              " ('state', 716),\n",
              " ('fast', 717),\n",
              " ('books', 718),\n",
              " ('8', 719),\n",
              " ('matter', 720),\n",
              " ('either', 721),\n",
              " ('kill', 722),\n",
              " ('sad', 723),\n",
              " ('act', 724),\n",
              " ('cuz', 725),\n",
              " ('dude', 726),\n",
              " ('dog', 727),\n",
              " ('bro', 728),\n",
              " ('yo', 729),\n",
              " ('means', 730),\n",
              " ('freshly', 731),\n",
              " ('cannot', 732),\n",
              " ('100', 733),\n",
              " ('challengeaccepted', 734),\n",
              " ('11', 735),\n",
              " ('second', 736),\n",
              " ('dad', 737),\n",
              " (\"what's\", 738),\n",
              " ('seconds', 739),\n",
              " ('single', 740),\n",
              " ('havent', 741),\n",
              " ('assignment', 742),\n",
              " ('0', 743),\n",
              " ('hello', 744),\n",
              " ('math', 745),\n",
              " ('deal', 746),\n",
              " ('wear', 747),\n",
              " ('career', 748),\n",
              " ('young', 749),\n",
              " ('downloaded', 750),\n",
              " ('knows', 751),\n",
              " ('doubt', 752),\n",
              " ('bandwagon', 753),\n",
              " ('mum', 754),\n",
              " ('distracted', 755),\n",
              " ('voice', 756),\n",
              " ('open', 757),\n",
              " ('using', 758),\n",
              " ('winning', 759),\n",
              " ('piece', 760),\n",
              " ('negative', 761),\n",
              " ('tattoos', 762),\n",
              " ('sometimes', 763),\n",
              " ('stress', 764),\n",
              " ('fans', 765),\n",
              " ('babe', 766),\n",
              " ('went', 767),\n",
              " ('took', 768),\n",
              " ('everyday', 769),\n",
              " ('instead', 770),\n",
              " ('justin', 771),\n",
              " ('amusing', 772),\n",
              " ('turn', 773),\n",
              " ('kid', 774),\n",
              " (\"you'll\", 775),\n",
              " ('sunday', 776),\n",
              " ('caught', 777),\n",
              " ('monday', 778),\n",
              " ('olduğunu', 779),\n",
              " ('zaman', 780),\n",
              " ('yalnız', 781),\n",
              " ('rn', 782),\n",
              " ('xx', 783),\n",
              " ('send', 784),\n",
              " ('laying', 785),\n",
              " ('question', 786),\n",
              " ('america', 787),\n",
              " ('truth', 788),\n",
              " ('trust', 789),\n",
              " ('picture', 790),\n",
              " ('cleaning', 791),\n",
              " ('😅', 792),\n",
              " ('vote', 793),\n",
              " ('huge', 794),\n",
              " ('answer', 795),\n",
              " ('braid', 796),\n",
              " ('android', 797),\n",
              " ('lose', 798),\n",
              " (\"couldn't\", 799),\n",
              " ('nigga', 800),\n",
              " ('anger', 801),\n",
              " ('problem', 802),\n",
              " ('future', 803),\n",
              " ('share', 804),\n",
              " ('mənim', 805),\n",
              " ('görə', 806),\n",
              " ('bütün', 807),\n",
              " ('lady', 808),\n",
              " ('pants', 809),\n",
              " ('worththewait', 810),\n",
              " ('far', 811),\n",
              " ('lord', 812),\n",
              " ('dressing', 813),\n",
              " ('holiday', 814),\n",
              " ('strong', 815),\n",
              " ('saw', 816),\n",
              " ('frustration', 817),\n",
              " ('seems', 818),\n",
              " ('light', 819),\n",
              " ('impressive', 820),\n",
              " ('die', 821),\n",
              " ('songs', 822),\n",
              " ('bitches', 823),\n",
              " ('mp3', 824),\n",
              " ('expect', 825),\n",
              " ('attracted', 826),\n",
              " ('forever', 827),\n",
              " ('obama', 828),\n",
              " ('crying', 829),\n",
              " ('holy', 830),\n",
              " ('forgot', 831),\n",
              " ('moment', 832),\n",
              " ('ugly', 833),\n",
              " ('sore', 834),\n",
              " ('barackobama', 835),\n",
              " ('walk', 836),\n",
              " ('12', 837),\n",
              " ('whitepeopleproblems', 838),\n",
              " ('p', 839),\n",
              " ('write', 840),\n",
              " ('less', 841),\n",
              " ('joy', 842),\n",
              " ('reading', 843),\n",
              " ('trip', 844),\n",
              " ('lots', 845),\n",
              " ('tweets', 846),\n",
              " ('pic', 847),\n",
              " ('fine', 848),\n",
              " ('coffee', 849),\n",
              " ('listening', 850),\n",
              " ('imagine', 851),\n",
              " ('missing', 852),\n",
              " ('mine', 853),\n",
              " ('😌', 854),\n",
              " ('dreams', 855),\n",
              " ('taking', 856),\n",
              " ('grass', 857),\n",
              " ('traffic', 858),\n",
              " ('ignorance', 859),\n",
              " ('britneyspears', 860),\n",
              " ('təşəkkür', 861),\n",
              " ('gecə', 862),\n",
              " ('sadəcə', 863),\n",
              " ('necə', 864),\n",
              " ('luck', 865),\n",
              " ('wife', 866),\n",
              " ('smh', 867),\n",
              " ('heartbroken', 868),\n",
              " ('auction', 869),\n",
              " ('cry', 870),\n",
              " ('visit', 871),\n",
              " ('brother', 872),\n",
              " ('running', 873),\n",
              " ('memories', 874),\n",
              " ('respect', 875),\n",
              " ('especially', 876),\n",
              " ('ones', 877),\n",
              " ('absolute', 878),\n",
              " (\"women's\", 879),\n",
              " ('body', 880),\n",
              " ('cigarette', 881),\n",
              " ('closer', 882),\n",
              " ('dancing', 883),\n",
              " ('highschool', 884),\n",
              " ('spend', 885),\n",
              " ('thinking', 886),\n",
              " ('easy', 887),\n",
              " ('sale', 888),\n",
              " ('character', 889),\n",
              " (\"wouldn't\", 890),\n",
              " ('others', 891),\n",
              " (\"aren't\", 892),\n",
              " ('babysit', 893),\n",
              " ('middle', 894),\n",
              " ('həqiqətən', 895),\n",
              " ('səhər', 896),\n",
              " ('vaxt', 897),\n",
              " ('bunu', 898),\n",
              " ('minutes', 899),\n",
              " ('15', 900),\n",
              " ('throw', 901),\n",
              " ('happened', 902),\n",
              " ('save', 903),\n",
              " ('attractive', 904),\n",
              " ('shows', 905),\n",
              " ('takes', 906),\n",
              " ('fail', 907),\n",
              " ('five', 908),\n",
              " ('event', 909),\n",
              " ('hockey', 910),\n",
              " ('health', 911),\n",
              " ('determined', 912),\n",
              " ('terrible', 913),\n",
              " ('costa', 914),\n",
              " ('games', 915),\n",
              " ('power', 916),\n",
              " ('shout', 917),\n",
              " ('scaring', 918),\n",
              " ('calling', 919),\n",
              " ('knowing', 920),\n",
              " ('definitely', 921),\n",
              " ('important', 922),\n",
              " ('knew', 923),\n",
              " ('finding', 924),\n",
              " ('straight', 925),\n",
              " ('bliss', 926),\n",
              " ('understatement', 927),\n",
              " ('♥', 928),\n",
              " ('takeaway', 929),\n",
              " ('short', 930),\n",
              " ('close', 931),\n",
              " ('blood', 932),\n",
              " ('hahaha', 933),\n",
              " ('valley', 934),\n",
              " ('become', 935),\n",
              " ('serving', 936),\n",
              " ('2nd', 937),\n",
              " ('level', 938),\n",
              " ('😴', 939),\n",
              " ('nightmare', 940),\n",
              " ('media', 941),\n",
              " ('extra', 942),\n",
              " ('public', 943),\n",
              " ('idiot', 944),\n",
              " ('plan', 945),\n",
              " ('feelings', 946),\n",
              " ('pls', 947),\n",
              " ('personal', 948),\n",
              " ('videos', 949),\n",
              " ('bet', 950),\n",
              " ('human', 951),\n",
              " ('cut', 952),\n",
              " ('sweat', 953),\n",
              " ('club', 954),\n",
              " ('four', 955),\n",
              " ('enjoyed', 956),\n",
              " ('suddenly', 957),\n",
              " ('secret', 958),\n",
              " ('government', 959),\n",
              " ('episode', 960),\n",
              " ('virginity', 961),\n",
              " ('living', 962),\n",
              " ('loves', 963),\n",
              " ('😋', 964),\n",
              " ('sex', 965),\n",
              " ('kinda', 966),\n",
              " ('inside', 967),\n",
              " ('calum5sos', 968),\n",
              " ('english', 969),\n",
              " ('yoxdur', 970),\n",
              " ('həmişə', 971),\n",
              " ('13', 972),\n",
              " ('bright', 973),\n",
              " ('interview', 974),\n",
              " ('streak', 975),\n",
              " ('rock', 976),\n",
              " ('eating', 977),\n",
              " ('adele', 978),\n",
              " ('winter', 979),\n",
              " ('roast', 980),\n",
              " ('couple', 981),\n",
              " ('busy', 982),\n",
              " ('facebook', 983),\n",
              " ('sun', 984),\n",
              " ('potus', 985),\n",
              " ('congrats', 986),\n",
              " ('missed', 987),\n",
              " ('looked', 988),\n",
              " ('amas', 989),\n",
              " ('flowing', 990),\n",
              " ('hidden', 991),\n",
              " ('line', 992),\n",
              " ('niggas', 993),\n",
              " ('group', 994),\n",
              " ('special', 995),\n",
              " ('bye', 996),\n",
              " ('explain', 997),\n",
              " ('thinks', 998),\n",
              " ('thats', 999),\n",
              " ('correction', 1000),\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiQRLvzGGNzm"
      },
      "source": [
        "tokenized=t.texts_to_sequences(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXhdLaniBUwn",
        "outputId": "4cd5414a-02d1-4953-f2a5-95120341f329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(map(len, tokenized))/len(tokenized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR54i8B6GN2p"
      },
      "source": [
        "import tensorflow.keras.preprocessing.sequence as seq\n",
        "\n",
        "ready_tweets = seq.pad_sequences(tokenized, maxlen=8, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBHmlPt4kVJI",
        "outputId": "501c9ad0-3c2e-4c19-eb5e-6f637c20d538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ready_tweets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIJNTiu4kVNk"
      },
      "source": [
        "x_train=ready_tweets[:8000]\n",
        "x_test=ready_tweets[8000:]\n",
        "train_labels=labels[:8000]\n",
        "test_labels=labels[8000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xewR3pTxf096"
      },
      "source": [
        "We can also take these three classes and make them binary.Lets compare binary and original labels to see,in which case model would perform better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNB4iiPVKQfZ"
      },
      "source": [
        "sarcasm,sarcasm and humor,humor,humor and insult,insult,sarcasm and insult,none"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cUm9LmIJqXp"
      },
      "source": [
        "train_labels_binary=np.zeros((8000,7))\n",
        "test_labels_binary=np.zeros((2000,7))\n",
        "for i in range(train_labels.shape[0]):\n",
        "  if train_labels[i][0]==1 and train_labels[i][1]==0 and train_labels[i][2]==0:\n",
        "    train_labels_binary[i,0]=1\n",
        "    train_labels_binary[i,1]=0\n",
        "    train_labels_binary[i,2]=0\n",
        "    train_labels_binary[i,3]=0\n",
        "    train_labels_binary[i,4]=0\n",
        "    train_labels_binary[i,5]=0\n",
        "    train_labels_binary[i,6]=0\n",
        "  elif train_labels[i][0]==1 and train_labels[i][1]==1 and train_labels[i][2]==0:\n",
        "    train_labels_binary[i,0]=0\n",
        "    train_labels_binary[i,1]=1\n",
        "    train_labels_binary[i,2]=0\n",
        "    train_labels_binary[i,3]=0\n",
        "    train_labels_binary[i,4]=0\n",
        "    train_labels_binary[i,5]=0\n",
        "    train_labels_binary[i,6]=0\n",
        "  elif train_labels[i][0]==0 and train_labels[i][1]==1 and train_labels[i][2]==0:\n",
        "    train_labels_binary[i,0]=0\n",
        "    train_labels_binary[i,1]=0\n",
        "    train_labels_binary[i,2]=1\n",
        "    train_labels_binary[i,3]=0\n",
        "    train_labels_binary[i,4]=0\n",
        "    train_labels_binary[i,5]=0\n",
        "    train_labels_binary[i,6]=0\n",
        "  elif train_labels[i][0]==0 and train_labels[i][1]==1 and train_labels[i][2]==1:\n",
        "    train_labels_binary[i,0]=0\n",
        "    train_labels_binary[i,1]=0\n",
        "    train_labels_binary[i,2]=0\n",
        "    train_labels_binary[i,3]=1\n",
        "    train_labels_binary[i,4]=0\n",
        "    train_labels_binary[i,5]=0\n",
        "    train_labels_binary[i,6]=0\n",
        "  elif train_labels[i][0]==0 and train_labels[i][1]==0 and train_labels[i][2]==1:\n",
        "    train_labels_binary[i,0]=0\n",
        "    train_labels_binary[i,1]=0\n",
        "    train_labels_binary[i,2]=0\n",
        "    train_labels_binary[i,3]=0\n",
        "    train_labels_binary[i,4]=1\n",
        "    train_labels_binary[i,5]=0\n",
        "    train_labels_binary[i,6]=0\n",
        "  elif train_labels[i][0]==1 and train_labels[i][1]==0 and train_labels[i][2]==1:\n",
        "    train_labels_binary[i,0]=0\n",
        "    train_labels_binary[i,1]=0\n",
        "    train_labels_binary[i,2]=0\n",
        "    train_labels_binary[i,3]=0\n",
        "    train_labels_binary[i,4]=0\n",
        "    train_labels_binary[i,5]=1\n",
        "    train_labels_binary[i,6]=0\n",
        "  elif train_labels[i][0]==0 and train_labels[i][1]==0 and train_labels[i][2]==0:\n",
        "    train_labels_binary[i,0]=0\n",
        "    train_labels_binary[i,1]=0\n",
        "    train_labels_binary[i,2]=0\n",
        "    train_labels_binary[i,3]=0\n",
        "    train_labels_binary[i,4]=0\n",
        "    train_labels_binary[i,5]=0\n",
        "    train_labels_binary[i,6]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFcMbceuSxxB"
      },
      "source": [
        "train_labels_binary=train_labels_binary.astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESzVeeeGgcLQ"
      },
      "source": [
        "Because I have multioutput and LR can't deal with multioutput,we need to use OnevsRest approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ6eoEAiBqfm",
        "outputId": "855e45f1-5c26-40d8-f0f3-9e887355e5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "clf=OneVsRestClassifier(LogisticRegression(random_state=45)).fit(x_train,train_labels_binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 1 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGOX60rKKHGl"
      },
      "source": [
        "for i in range(test_labels.shape[0]):\n",
        "  if test_labels[i][0]==1 and test_labels[i][1]==0 and test_labels[i][2]==0:\n",
        "    test_labels_binary[i,0]=1\n",
        "    test_labels_binary[i,1]=0\n",
        "    test_labels_binary[i,2]=0\n",
        "    test_labels_binary[i,3]=0\n",
        "    test_labels_binary[i,4]=0\n",
        "    test_labels_binary[i,5]=0\n",
        "    test_labels_binary[i,6]=0\n",
        "  elif test_labels[i][0]==1 and test_labels[i][1]==1 and test_labels[i][2]==0:\n",
        "    test_labels_binary[i,0]=0\n",
        "    test_labels_binary[i,1]=1\n",
        "    test_labels_binary[i,2]=0\n",
        "    test_labels_binary[i,3]=0\n",
        "    test_labels_binary[i,4]=0\n",
        "    test_labels_binary[i,5]=0\n",
        "    test_labels_binary[i,6]=0\n",
        "  elif test_labels[i][0]==0 and test_labels[i][1]==1 and test_labels[i][2]==0:\n",
        "    test_labels_binary[i,0]=0\n",
        "    test_labels_binary[i,1]=0\n",
        "    test_labels_binary[i,2]=1\n",
        "    test_labels_binary[i,3]=0\n",
        "    test_labels_binary[i,4]=0\n",
        "    test_labels_binary[i,5]=0\n",
        "    test_labels_binary[i,6]=0\n",
        "  elif test_labels[i][0]==0 and test_labels[i][1]==1 and test_labels[i][2]==1:\n",
        "    test_labels_binary[i,0]=0\n",
        "    test_labels_binary[i,1]=0\n",
        "    test_labels_binary[i,2]=0\n",
        "    test_labels_binary[i,3]=1\n",
        "    test_labels_binary[i,4]=0\n",
        "    test_labels_binary[i,5]=0\n",
        "    test_labels_binary[i,6]=0\n",
        "  elif test_labels[i][0]==0 and test_labels[i][1]==0 and test_labels[i][2]==1:\n",
        "    test_labels_binary[i,0]=0\n",
        "    test_labels_binary[i,1]=0\n",
        "    test_labels_binary[i,2]=0\n",
        "    test_labels_binary[i,3]=0\n",
        "    test_labels_binary[i,4]=1\n",
        "    test_labels_binary[i,5]=0\n",
        "    test_labels_binary[i,6]=0\n",
        "  elif test_labels[i][0]==1 and test_labels[i][1]==0 and test_labels[i][2]==1:\n",
        "    test_labels_binary[i,0]=0\n",
        "    test_labels_binary[i,1]=0\n",
        "    test_labels_binary[i,2]=0\n",
        "    test_labels_binary[i,3]=0\n",
        "    test_labels_binary[i,4]=0\n",
        "    test_labels_binary[i,5]=1\n",
        "    test_labels_binary[i,6]=0\n",
        "  elif test_labels[i][0]==0 and test_labels[i][1]==0 and test_labels[i][2]==0:\n",
        "    test_labels_binary[i,0]=0\n",
        "    test_labels_binary[i,1]=0\n",
        "    test_labels_binary[i,2]=0\n",
        "    test_labels_binary[i,3]=0\n",
        "    test_labels_binary[i,4]=0\n",
        "    test_labels_binary[i,5]=0\n",
        "    test_labels_binary[i,6]=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxPM6cq1Bqia",
        "outputId": "cd90e629-5ff2-4830-fda7-d8683befbaf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(x_test,test_labels_binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO-2N9cMgPi8"
      },
      "source": [
        "5% is really bad result,so the theory,that more labels you have,the less is accuracy,is absolutely true"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIOdgoa6Bqk7",
        "outputId": "332a16fb-c016-4316-aa67-9ed3a57004d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "np.random.seed(349)\n",
        "clf_2=OneVsRestClassifier(LogisticRegression(random_state=38)).fit(x_train,train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YnM9eEnJcwd",
        "outputId": "e9fe6fe5-1ac2-4238-a8ed-b0a8deeb475f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf_2.score(x_test,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbFcDkiLg-m0"
      },
      "source": [
        "When we use three labels,the result is much better.We have 6 different outputs in this case,so this means,that model has learnt something"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KcAq1MAMAv2"
      },
      "source": [
        "100/6=16.6666666667\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh85ZNCsL5bq",
        "outputId": "8ac12981-3943-4ea5-a185-d8697b695f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=['lumos Azərbaycanin ən böyük kursu sayilir']\n",
        "sentence=t.texts_to_sequences(sentence)\n",
        "sentence=seq.pad_sequences(sentence, maxlen=8, padding='post', truncating='post')\n",
        "clf_2.predict(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYovWNXCON5A"
      },
      "source": [
        "It is not sarcasm,not humor and not insult.Even ML says,that lumos is the best!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWZgAqyVJc4M",
        "outputId": "fdc22ee9-1faa-40c2-a3de-f9359bb6550c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=['Ilhami bütün Azerbaycan söyür']\n",
        "sentence=t.texts_to_sequences(sentence)\n",
        "sentence=seq.pad_sequences(sentence, maxlen=8, padding='post', truncating='post')\n",
        "clf_2.predict(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DPQ4wacOhju"
      },
      "source": [
        "ML says that it is a humor and insult.Cool!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXBSDd1VJczE",
        "outputId": "4fd8b26c-c09e-49b7-b3a9-0c7492ae30c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=['sabir will have a  girlfriend']\n",
        "sentence=t.texts_to_sequences(sentence)\n",
        "sentence=seq.pad_sequences(sentence, maxlen=8, padding='post', truncating='post')\n",
        "clf_2.predict(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pvOp2LRPvzt"
      },
      "source": [
        "So,it is  insult!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4gv46mTMyYU",
        "outputId": "e28a0e5e-e1f0-47a5-9691-ade6b77ed4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentence=['Sexual assault is what makes Azerbaijan so unique!']\n",
        "sentence=t.texts_to_sequences(sentence)\n",
        "sentence=seq.pad_sequences(sentence, maxlen=8, padding='post', truncating='post')\n",
        "clf_2.predict(sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoOZvlYXQUE7"
      },
      "source": [
        "Humor and insult!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVleygsghSXE"
      },
      "source": [
        "The second way:\n",
        "\n",
        "*   Take the overall dataset and tokenize the text in char level.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Disadvantage of this method is these two languages have lots of same letters,so it will be confusing for LR to learn patterns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNSIlU_XMybO"
      },
      "source": [
        "import tensorflow as tf\n",
        "char_tokenizer=tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=60, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
        "    split=' ', char_level=True, oov_token = 'sabir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBHoweFyMyhl"
      },
      "source": [
        "tweets=np.array(overall['tweet'])\n",
        "labels=np.array(overall[['sarcasm','humor','insult']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3oEHJJJXWyO"
      },
      "source": [
        "char_tokenizer.fit_on_texts(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8s5UuofMymp",
        "outputId": "7d2a882c-9b72-4ca2-cd3f-51ec0237c087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sorted(char_tokenizer.word_index.items(),key=lambda x:x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sabir', 1),\n",
              " (' ', 2),\n",
              " ('e', 3),\n",
              " ('a', 4),\n",
              " ('t', 5),\n",
              " ('o', 6),\n",
              " ('i', 7),\n",
              " ('n', 8),\n",
              " ('s', 9),\n",
              " ('r', 10),\n",
              " ('l', 11),\n",
              " ('h', 12),\n",
              " ('d', 13),\n",
              " ('u', 14),\n",
              " ('y', 15),\n",
              " ('m', 16),\n",
              " ('g', 17),\n",
              " ('c', 18),\n",
              " ('w', 19),\n",
              " ('b', 20),\n",
              " ('f', 21),\n",
              " ('p', 22),\n",
              " ('k', 23),\n",
              " ('v', 24),\n",
              " ('.', 25),\n",
              " (\"'\", 26),\n",
              " ('ə', 27),\n",
              " ('@', 28),\n",
              " ('#', 29),\n",
              " (',', 30),\n",
              " ('!', 31),\n",
              " ('x', 32),\n",
              " ('j', 33),\n",
              " ('ı', 34),\n",
              " ('z', 35),\n",
              " ('ü', 36),\n",
              " ('q', 37),\n",
              " ('?', 38),\n",
              " ('\"', 39),\n",
              " ('1', 40),\n",
              " ('ş', 41),\n",
              " ('-', 42),\n",
              " (':', 43),\n",
              " ('_', 44),\n",
              " ('2', 45),\n",
              " ('0', 46),\n",
              " ('ç', 47),\n",
              " ('&', 48),\n",
              " ('😂', 49),\n",
              " ('5', 50),\n",
              " ('3', 51),\n",
              " ('ğ', 52),\n",
              " ('ö', 53),\n",
              " (')', 54),\n",
              " ('4', 55),\n",
              " ('9', 56),\n",
              " ('❤', 57),\n",
              " ('️', 58),\n",
              " ('/', 59),\n",
              " ('(', 60),\n",
              " ('6', 61),\n",
              " ('7', 62),\n",
              " ('8', 63),\n",
              " ('😍', 64),\n",
              " ('😭', 65),\n",
              " ('😘', 66),\n",
              " ('😊', 67),\n",
              " ('*', 68),\n",
              " ('😩', 69),\n",
              " (';', 70),\n",
              " ('̇', 71),\n",
              " ('😒', 72),\n",
              " ('$', 73),\n",
              " ('%', 74),\n",
              " ('😁', 75),\n",
              " ('☺', 76),\n",
              " ('+', 77),\n",
              " ('—', 78),\n",
              " ('~', 79),\n",
              " ('�', 80),\n",
              " ('😔', 81),\n",
              " ('😷', 82),\n",
              " ('💙', 83),\n",
              " ('😑', 84),\n",
              " ('|', 85),\n",
              " ('😉', 86),\n",
              " ('^', 87),\n",
              " ('😅', 88),\n",
              " ('😌', 89),\n",
              " ('♥', 90),\n",
              " ('=', 91),\n",
              " ('😎', 92),\n",
              " ('🎈', 93),\n",
              " ('😀', 94),\n",
              " ('😜', 95),\n",
              " ('😈', 96),\n",
              " ('😴', 97),\n",
              " ('😏', 98),\n",
              " ('😋', 99),\n",
              " ('😡', 100),\n",
              " ('😢', 101),\n",
              " ('😞', 102),\n",
              " ('😝', 103),\n",
              " ('✨', 104),\n",
              " ('😄', 105),\n",
              " ('😹', 106),\n",
              " ('😫', 107),\n",
              " ('😐', 108),\n",
              " ('✌', 109),\n",
              " ('🎂', 110),\n",
              " ('😖', 111),\n",
              " ('😪', 112),\n",
              " ('😕', 113),\n",
              " ('☕', 114),\n",
              " ('✊', 115),\n",
              " ('😛', 116),\n",
              " ('[', 117),\n",
              " ('😳', 118),\n",
              " ('😻', 119),\n",
              " ('🎁', 120),\n",
              " (']', 121),\n",
              " ('❄', 122),\n",
              " ('😓', 123),\n",
              " ('🎊', 124),\n",
              " ('\\u200b', 125),\n",
              " ('–', 126),\n",
              " ('👑', 127),\n",
              " ('♡', 128),\n",
              " ('😇', 129),\n",
              " ('🎤', 130),\n",
              " ('😃', 131),\n",
              " ('😣', 132),\n",
              " ('😆', 133),\n",
              " ('💗', 134),\n",
              " ('\\xa0', 135),\n",
              " ('🚮', 136),\n",
              " ('👸', 137),\n",
              " ('‘', 138),\n",
              " ('😚', 139),\n",
              " ('⚽', 140),\n",
              " ('😠', 141),\n",
              " ('£', 142),\n",
              " ('😙', 143),\n",
              " ('❣', 144),\n",
              " ('🌸', 145),\n",
              " ('{', 146),\n",
              " ('😱', 147),\n",
              " ('🌞', 148),\n",
              " ('☀', 149),\n",
              " ('🇸', 150),\n",
              " ('🎉', 151),\n",
              " ('}', 152),\n",
              " ('\\u200d', 153),\n",
              " ('☹', 154),\n",
              " ('🏈', 155),\n",
              " ('á', 156),\n",
              " ('💖', 157),\n",
              " ('💞', 158),\n",
              " ('😥', 159),\n",
              " ('\\\\', 160),\n",
              " ('👋', 161),\n",
              " ('💜', 162),\n",
              " ('🇬', 163),\n",
              " ('🇧', 164),\n",
              " ('🌃', 165),\n",
              " ('🤑', 166),\n",
              " ('🐟', 167),\n",
              " ('✔', 168),\n",
              " ('―', 169),\n",
              " ('👐', 170),\n",
              " ('💸', 171),\n",
              " ('¡', 172),\n",
              " ('🐸', 173),\n",
              " ('💐', 174),\n",
              " ('🐷', 175),\n",
              " ('💫', 176),\n",
              " ('👶', 177),\n",
              " ('×', 178),\n",
              " ('🍟', 179),\n",
              " ('🏿', 180),\n",
              " ('…', 181),\n",
              " ('✈', 182),\n",
              " ('👧', 183),\n",
              " ('🙇', 184),\n",
              " ('🍫', 185),\n",
              " ('🐔', 186),\n",
              " ('\\x92', 187),\n",
              " ('•', 188),\n",
              " ('🎥', 189),\n",
              " ('´', 190),\n",
              " ('🍾', 191),\n",
              " ('💍', 192),\n",
              " ('👩', 193),\n",
              " ('🌳', 194),\n",
              " ('😦', 195),\n",
              " ('ү', 196),\n",
              " ('🌲', 197),\n",
              " ('🍗', 198),\n",
              " ('🍴', 199),\n",
              " ('👪', 200),\n",
              " ('📖', 201),\n",
              " ('🍓', 202),\n",
              " ('💌', 203),\n",
              " ('😲', 204),\n",
              " ('♪', 205),\n",
              " ('é', 206),\n",
              " ('📝', 207),\n",
              " ('🚽', 208),\n",
              " ('💛', 209),\n",
              " ('©', 210),\n",
              " ('`', 211),\n",
              " ('🙌', 212),\n",
              " ('👦', 213),\n",
              " ('💕', 214),\n",
              " ('🌍', 215),\n",
              " ('😗', 216),\n",
              " ('👀', 217),\n",
              " ('🌬', 218),\n",
              " ('🐻', 219),\n",
              " ('<', 220),\n",
              " ('💷', 221),\n",
              " ('🍰', 222),\n",
              " ('👗', 223),\n",
              " ('🍸', 224),\n",
              " ('❗', 225),\n",
              " ('🎇', 226),\n",
              " ('🏼', 227),\n",
              " ('👍', 228),\n",
              " ('✋', 229),\n",
              " ('↺', 230),\n",
              " ('😽', 231),\n",
              " ('🌯', 232),\n",
              " ('😟', 233),\n",
              " ('ㅠ', 234),\n",
              " ('👼', 235),\n",
              " ('‼', 236),\n",
              " ('🌝', 237),\n",
              " ('😰', 238),\n",
              " ('😼', 239),\n",
              " ('🍿', 240),\n",
              " ('»', 241),\n",
              " ('⛄', 242),\n",
              " ('🏹', 243),\n",
              " ('🔞', 244),\n",
              " ('🐯', 245),\n",
              " ('😨', 246),\n",
              " ('🏦', 247),\n",
              " ('💄', 248),\n",
              " ('🅿', 249),\n",
              " ('╽', 250),\n",
              " ('🎄', 251),\n",
              " ('👳', 252),\n",
              " ('🌵', 253),\n",
              " ('🔓', 254),\n",
              " ('🌽', 255),\n",
              " ('🌪', 256),\n",
              " ('⚓', 257),\n",
              " ('🌟', 258),\n",
              " ('🌌', 259),\n",
              " ('🍇', 260),\n",
              " ('🍭', 261),\n",
              " ('🍀', 262),\n",
              " ('⚡', 263),\n",
              " ('🐏', 264),\n",
              " ('👲', 265),\n",
              " ('\\U000fe327', 266),\n",
              " ('\\U000feb9f', 267),\n",
              " ('🍝', 268),\n",
              " ('🚗', 269),\n",
              " ('🗣', 270),\n",
              " ('🇵', 271),\n",
              " ('😿', 272),\n",
              " ('👫', 273),\n",
              " ('🔐', 274),\n",
              " ('🐑', 275),\n",
              " ('🏐', 276),\n",
              " ('⚠', 277),\n",
              " ('🎶', 278),\n",
              " ('🏏', 279),\n",
              " ('🌼', 280),\n",
              " ('👌', 281),\n",
              " ('😧', 282),\n",
              " ('🌎', 283),\n",
              " ('⭕', 284),\n",
              " ('🍼', 285),\n",
              " ('🍎', 286),\n",
              " ('🍏', 287),\n",
              " ('🏡', 288),\n",
              " ('😶', 289),\n",
              " ('🚂', 290),\n",
              " ('⭐', 291),\n",
              " ('🖼', 292),\n",
              " ('🦃', 293),\n",
              " ('✂', 294),\n",
              " ('🐀', 295),\n",
              " ('🙏', 296),\n",
              " ('👅', 297),\n",
              " ('ñ', 298),\n",
              " ('🗽', 299),\n",
              " ('🇺', 300),\n",
              " ('📻', 301),\n",
              " ('📺', 302),\n",
              " ('「', 303),\n",
              " ('」', 304),\n",
              " ('⛈', 305),\n",
              " ('✩', 306),\n",
              " ('더', 307),\n",
              " ('쇼', 308),\n",
              " ('🐊', 309),\n",
              " ('🍕', 310),\n",
              " ('⬆', 311),\n",
              " ('™', 312),\n",
              " ('🌺', 313),\n",
              " ('🐾', 314),\n",
              " ('🏆', 315),\n",
              " ('갓', 316),\n",
              " ('제', 317),\n",
              " ('븐', 318),\n",
              " ('«', 319),\n",
              " ('😮', 320),\n",
              " ('🎆', 321),\n",
              " ('🍒', 322),\n",
              " ('🇦', 323),\n",
              " ('💝', 324),\n",
              " ('🔷', 325),\n",
              " ('👨', 326),\n",
              " ('🚊', 327),\n",
              " ('🌅', 328),\n",
              " ('🚡', 329),\n",
              " ('🌈', 330),\n",
              " ('ღ', 331),\n",
              " ('🙂', 332),\n",
              " ('🏒', 333),\n",
              " ('😺', 334),\n",
              " ('🎵', 335),\n",
              " ('→', 336),\n",
              " ('🔒', 337),\n",
              " ('👵', 338),\n",
              " ('『', 339),\n",
              " ('』', 340),\n",
              " ('☝', 341),\n",
              " ('🙄', 342),\n",
              " ('🔋', 343),\n",
              " ('🍥', 344),\n",
              " ('↓', 345),\n",
              " ('🐼', 346),\n",
              " ('\\x93', 347),\n",
              " ('\\x94', 348),\n",
              " ('💦', 349),\n",
              " ('🐱', 350),\n",
              " ('🤕', 351),\n",
              " ('👿', 352),\n",
              " ('°', 353),\n",
              " ('ë', 354),\n",
              " ('기', 355),\n",
              " ('현', 356),\n",
              " ('데', 357),\n",
              " ('이', 358),\n",
              " ('🗿', 359),\n",
              " ('🌨', 360),\n",
              " ('⛪', 361),\n",
              " ('📱', 362),\n",
              " ('🙈', 363),\n",
              " ('👠', 364),\n",
              " ('💑', 365),\n",
              " ('🍁', 366),\n",
              " ('🍂', 367),\n",
              " ('🌤', 368),\n",
              " ('’', 369),\n",
              " ('🔦', 370),\n",
              " ('👎', 371),\n",
              " ('🚶', 372),\n",
              " ('¿', 373)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycNDxyKnV0XP"
      },
      "source": [
        "tokenized=char_tokenizer.texts_to_sequences(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCvHK64ZV0aW"
      },
      "source": [
        "num=[]\n",
        "for sentence in tokenized:\n",
        "  num.append(len(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Il2A_DiYTvt",
        "outputId": "5e0d8456-b32b-4555-d911-653350a45d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.percentile(num,50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzSmjVdTV0c1"
      },
      "source": [
        "import tensorflow.keras.preprocessing.sequence as seq\n",
        "\n",
        "overall_tweets = seq.pad_sequences(tokenized, maxlen=85, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKc0h68BV0g1"
      },
      "source": [
        "x_train=overall_tweets[:8000]\n",
        "x_test=overall_tweets[8000:]\n",
        "train_labels=labels[:8000]\n",
        "test_labels=labels[8000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujRW56afXomm",
        "outputId": "23cd5c83-6f23-4869-9f3d-7b237d4045fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "clf_char=OneVsRestClassifier(LogisticRegression(random_state=78)).fit(x_train,train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ZBbul1XopX",
        "outputId": "41f09c67-b611-4263-820a-32f0502857ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf_char.score(x_test,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.197"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xBqLlaYh52F"
      },
      "source": [
        "Result is slightly better than previous one,but this method is not the best"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDm7Mn6kiD5y"
      },
      "source": [
        "The third way is:\n",
        "\n",
        "*   Take two separate datasets(original and translated tweets) and train them separately\n",
        "\n",
        "\n",
        "\n",
        "Advantage of this method is model learns these two languages separately,so model avoids any confusion\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsQpalbOXor4"
      },
      "source": [
        "azerbaijani_tweets=np.array(azerbaijani_dataset['tweet'])\n",
        "labels=np.array(azerbaijani_dataset[['sarcasm','humor','insult']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPvf6FhmXoxH"
      },
      "source": [
        "import tensorflow as tf\n",
        "t=tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=50, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
        "    split=' ', char_level=True, oov_token = 'sabir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2S50VBUZqSG"
      },
      "source": [
        "t.fit_on_texts(azerbaijani_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4soMuvqZqU0"
      },
      "source": [
        "tokenized=t.texts_to_sequences(azerbaijani_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PPW_yMHaXbt",
        "outputId": "19e2347f-e2f2-447e-caf6-af6ace3e97a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num=[]\n",
        "for sentence in tokenized:\n",
        "  num.append(len(sentence))\n",
        "np.percentile(num,50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg56ptPHZqYj"
      },
      "source": [
        "import tensorflow.keras.preprocessing.sequence as seq\n",
        "\n",
        "ready_tweets = seq.pad_sequences(tokenized, maxlen=88, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61zavCOBZqdL"
      },
      "source": [
        "x_train=ready_tweets[:800]\n",
        "x_test=ready_tweets[800:]\n",
        "train_labels=labels[:800]\n",
        "test_labels=labels[800:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwbfNoS6ZqbM"
      },
      "source": [
        "clf_char_az=OneVsRestClassifier(LogisticRegression(random_state=78)).fit(x_train,train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTorsi6fayoO",
        "outputId": "101ce049-c1fd-4cd1-f4d4-420215ab0d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf_char_az.score(x_test,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xvg6drQbC3b"
      },
      "source": [
        "original_tweets=np.array(all_comments['tweet'])\n",
        "labels=np.array(all_comments[['sarcasm','humor','insult']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcEU-HJxbC6l"
      },
      "source": [
        "t=tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=50, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
        "    split=' ', char_level=True, oov_token = 'sabir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDshb9pObDCY"
      },
      "source": [
        "t.fit_on_texts(original_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_A4lUhYbDHj"
      },
      "source": [
        "tokenized=t.texts_to_sequences(original_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CORHQxokbDFe",
        "outputId": "de0b4d9d-60d5-46a0-c4c9-b0974cdcfc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "num=[]\n",
        "for sentence in tokenized:\n",
        "  num.append(len(sentence))\n",
        "np.percentile(num,50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sWcyrJUbDAC"
      },
      "source": [
        "ready_tweets = seq.pad_sequences(tokenized, maxlen=85, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCd5my0BbC9s",
        "outputId": "32b193be-9433-4931-bdb7-20aba4923cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train=ready_tweets[:7500]\n",
        "x_test=ready_tweets[7500:]\n",
        "train_labels=labels[:7500]\n",
        "test_labels=labels[7500:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5COf_Kq9bbTY",
        "outputId": "94fc9d69-e16d-4a0c-ffb2-e84384980dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "clf_char_en=OneVsRestClassifier(LogisticRegression(random_state=78)).fit(x_train,train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsGPgLSXbd8A",
        "outputId": "a722abd1-f3b3-4ddb-9e2f-5c3a137c57c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf_char_en.score(x_test,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25466666666666665"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6S8tb41ioCg"
      },
      "source": [
        "This method is more better,and we have 25% accuracy,which is really great"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gKh94aYi228"
      },
      "source": [
        "In all of these cases I used imbalanced dataset.Lets balance it!I will use 5000 Azerbaijani samples and 5000 original samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kdujBnXiyHB"
      },
      "source": [
        "all_comments=pd.read_csv('/content/sarcasmania-dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XtBBljbiyJ6"
      },
      "source": [
        "np.random.seed(128)\n",
        "shuffled_comments=all_comments.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ11pYMkiyO7"
      },
      "source": [
        "shuffled_comments=shuffled_comments.iloc[:5000,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwfCtcuRiySH"
      },
      "source": [
        "az_tweets=[]\n",
        "for tweet in shuffled_comments['tweet']:\n",
        "  translation=translator.translate(tweet,src='en',dest='az')\n",
        "  az_tweets.append(translation.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsdrfkW5iyNA"
      },
      "source": [
        "sarcasm=shuffled_comments.iloc[:5000,2]\n",
        "humor=shuffled_comments.iloc[:5000,3]\n",
        "insult=shuffled_comments.iloc[:5000,4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdhj7bVPjmth"
      },
      "source": [
        "azerbaijani_dataset=pd.DataFrame({'tweet':az_tweets,'sarcasm':sarcasm,'humor':humor,'insult':insult})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZDgELsJjm0o"
      },
      "source": [
        "all_comments=all_comments.iloc[:5000,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47cn8DjUjm_P"
      },
      "source": [
        "overall=pd.concat([all_comments,azerbaijani_dataset])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BklMYyh5jm6n"
      },
      "source": [
        "np.random.seed(130)\n",
        "shuffled_overall=overall.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWTZPZkTjm4y"
      },
      "source": [
        "t=tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=60, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,\n",
        "    split=' ', char_level=True, oov_token = 'sabir')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN99jEa3jmyq"
      },
      "source": [
        "tweets=np.array(overall['tweet'])\n",
        "labels=np.array(overall[['sarcasm','humor','insult']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQFA0QX5jmwL"
      },
      "source": [
        "t.fit_on_texts(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NplAt-xykGgG"
      },
      "source": [
        "tokenized=t.texts_to_sequences(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-yvPgjYkbmP",
        "outputId": "8d97705a-e55c-4c0e-82e0-ae1bf60ac427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(map(len, tokenized))/len(tokenized)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "89.4417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A7HOaGNkGlK"
      },
      "source": [
        "ready_tweets = seq.pad_sequences(tokenized, maxlen=89, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyjlcxtwkGuR"
      },
      "source": [
        "x_train=ready_tweets[:8000]\n",
        "x_test=ready_tweets[8000:]\n",
        "train_labels=labels[:8000]\n",
        "test_labels=labels[8000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKaBSaYqkGya"
      },
      "source": [
        "clf=OneVsRestClassifier(LogisticRegression(random_state=45)).fit(x_train,train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3WPztMhkGs3",
        "outputId": "d29892b8-6d55-4302-c9a9-c5371c7d5d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.score(x_test,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iupToXIpT4mK"
      },
      "source": [
        "The reason why results are not so good is because dataset was not so much good.Or maybe we need much more samples."
      ]
    }
  ]
}